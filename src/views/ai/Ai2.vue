<template>
  <div><div class="grid-cols-1 grid gap-2.5 [&amp;_&gt;_*]:min-w-0 !gap-3.5"><h1 class="text-2xl font-bold mt-1 text-text-100">Базовая терминология по AI: уровень "User"</h1>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:00:00 - Введение в серию и целевая аудитория</h2>
    <p class="whitespace-normal break-words">Это второе видео из серии про базовую терминологию для тех, кто работает с AI в программировании. В предыдущем видео мы разговаривали про самую базовую терминологию, терминологию уровня новичок. Сегодня поговорим про терминологию уровня юзер — для тех людей, которые в повседневной жизни активно используют генеративные нейросети, генеративные модели для каких-то своих простых задач, но еще не для профессиональных программерских.</p>
    <p class="whitespace-normal break-words">Такой терминологии много и ее тоже надо освоить для того, чтобы лучше разбираться. Если вам влом смотреть видео, вы не аудиал и не визуал, то можете почитать файлик — называется «База программирования по искусственному интеллекту», который лежит в сообществе. Там, в принципе, вся терминология текстом красивенько изложена, буквально на 20 страниц PDF-ка. Можете ее быстренько пробежать глазами. Если же вы любите послушать мысли, если вы любите послушать чуть больше, чем в этом файле, то you're welcome, вы в правильном месте.</p>
    <p class="whitespace-normal break-words">Напоминаю, что я не исследователь, у меня нет звания доктора, я даже не ML-разработчик и не data scientist, я программист, а также человек, который последние несколько лет очень сильно погружен в AI, в программирование, в создание контента. Поэтому могу делать какие-то ошибки в терминологии, и вы не серчайте, просто напишите в комментариях, что вот тут ошибочка, и я как минимум в текстовом файлике это поправлю.</p>
    <p class="whitespace-normal break-words">Но опыта хватает для того, чтобы вам простым, буду пытаться простым языком объяснить термины, которые потом уже в практических задачах вам просто в ваше ДНК лягут с более строгой формулировкой. А моя задача — объяснить максимально просто те вещи, которые вам понадобятся. В общем, поехали.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:01:35 - Общее введение в терминологию уровня "User"</h2>
    <p class="whitespace-normal break-words">Сегодня у нас уровень юзер, и начну этот уровень с небольшой цитаты, небольшого summary. Погружаемся в этом разделе в терминологию, которая необходима для базовой работы с LLM, Large Language Model. Замечу, что эта терминология является общей для генеративных моделей. Это касается не только LLM, то есть не только моделей, которые работают с текстовыми данными в основном.</p>
    <p class="whitespace-normal break-words">Эта терминология уже может звучать слегка сложно, но на самом деле когда вы приходите в практику, то это все оказывается очень просто. Поэтому при просмотре видео, либо после просмотра пойдите и попробуйте ручками, и вы поймете, что это не так уж и, блин, сложно, как может звучать.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:02:36 - Промпт (Prompt)</h2>
    <p class="whitespace-normal break-words">Начнем наше знакомство с самого частого слова, самого пафосного, как по мне, слова — слово <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">промпт</code>. Это, по факту, любое текстовое сообщение, которое вы отправляете в нейронку. Просто текстовое сообщение, которое мы отправляем в модель и ожидаем на него ответ.</p>
    <p class="whitespace-normal break-words">Для него придумали слово «промпт», там даже есть ответвление от этого слова, но по факту придумали модное слово для вполне себе обычного явления отправки пользовательского сообщения, не только пользовательского, кстати, в нейроночку. Вот это вот Prompt. You're welcome. Теперь вы стали умнее.</p>
    <h3 class="text-lg font-bold text-text-100 mt-1 -mb-1.5">Примеры интерфейсов с промптами</h3>
    <p class="whitespace-normal break-words">Как Prompt может выглядеть? Например, вот так Prompt может выглядеть, точнее, вот так Prompt выглядит в чате GPT. Есть окошечко, вы вводите туда сообщение, и получаете ответ.</p>
    <p class="whitespace-normal break-words">Вот так Prompt выглядит в Claude AI. Тоже окошечко ввода, пишете что-то, получаете ответ.</p>
    <p class="whitespace-normal break-words">Вот так Prompt выглядит в Perplexity, в очень хорошем крутом поисковике. Все то же самое. Обычный input, в который мы пишем задачу, предложение, вопрос и получаем на это ответ.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:03:58 - Промпт-инженерия (Prompt Engineering)</h2>
    <p class="whitespace-normal break-words">Prompt породил модное словосочетание, в частности Prompt-инженерия, про которую разработчики, не знающие, думают, что это вау, какая-то новая сфера в разработке, там прям каких-то инженеров ищут, которые просто пишут сообщение и получают за это бабки? Нет, это не так.</p>
    <p class="whitespace-normal break-words">Промпт-инженерия в целом, либо промпт-инжиниринг, как его еще называют, промптинг — это умение, да, правильно составить промпт. Но правильно составить промпт — это не просто написать сообщеньку, которая правильно ответит, либо максимально точно ответит. Существует множество техник для того, как составлять промпты эффективно.</p>
    <p class="whitespace-normal break-words">Более того, существуют техники сложные, когда надо программировать поведение составления промпта, чтобы промпт составлялся из разных составных частей, возможно, на основании даже других промптов. Нужно знать какие-то лайфхаки того, как правильно задать вопрос, как подать, может быть, несколько примеров, чтобы нейросеть лучше вам ответила.</p>
    <p class="whitespace-normal break-words">В общем, люди, овладевшие этими техниками, они гордо зовут себя промпт-инженерами, либо промпт-инженерс. И это не отдельная специальность в разработке, это скорее навык. Навык правильного написания промпта. Навык написания вот так, чтобы модель дала наиболее точный и полезный ответ. И для этого есть разные техники.</p>
    <h3 class="text-lg font-bold text-text-100 mt-1 -mb-1.5">Пример профессионального промпта</h3>
    <p class="whitespace-normal break-words">Недостаточно просто знать, где находится поле, в которое надо ввести какой-то там текст. Вот так вот, например, может выглядеть хороший такой промпт для того, чтобы нейросеть выдавала хороший ответ по программированию:</p>
    <div class="relative group/copy bg-bg-000/50 border-0.5 border-border-400 rounded-lg"><div class="sticky opacity-0 group-hover/copy:opacity-100 top-2 py-2 h-12 w-0 float-right"><div class="absolute right-0 h-8 px-2 items-center inline-flex z-10"><button class="inline-flex
  items-center
  justify-center
  relative
  shrink-0
  can-focus
  select-none
  disabled:pointer-events-none
  disabled:opacity-50
  disabled:shadow-none
  disabled:drop-shadow-none border-transparent
          transition
          font-base
          duration-300
          ease-[cubic-bezier(0.165,0.85,0.45,1)] h-8 w-8 rounded-md active:scale-95 backdrop-blur-md Button_ghost__Ywhj1" type="button" aria-label="Copy to clipboard" data-state="closed"><div class="relative"><div class="flex items-center justify-center transition-all opacity-100 scale-100" style="width: 20px; height: 20px;"><svg width="20" height="20" viewBox="0 0 20 20" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="shrink-0 transition-all opacity-100 scale-100" aria-hidden="true"><path d="M10 1.5C11.1097 1.5 12.0758 2.10424 12.5947 3H14.5C15.3284 3 16 3.67157 16 4.5V16.5C16 17.3284 15.3284 18 14.5 18H5.5C4.67157 18 4 17.3284 4 16.5V4.5C4 3.67157 4.67157 3 5.5 3H7.40527C7.92423 2.10424 8.89028 1.5 10 1.5ZM5.5 4C5.22386 4 5 4.22386 5 4.5V16.5C5 16.7761 5.22386 17 5.5 17H14.5C14.7761 17 15 16.7761 15 16.5V4.5C15 4.22386 14.7761 4 14.5 4H12.958C12.9853 4.16263 13 4.32961 13 4.5V5.5C13 5.77614 12.7761 6 12.5 6H7.5C7.22386 6 7 5.77614 7 5.5V4.5C7 4.32961 7.0147 4.16263 7.04199 4H5.5ZM12.54 13.3037C12.6486 13.05 12.9425 12.9317 13.1963 13.04C13.45 13.1486 13.5683 13.4425 13.46 13.6963C13.1651 14.3853 12.589 15 11.7998 15C11.3132 14.9999 10.908 14.7663 10.5996 14.4258C10.2913 14.7661 9.88667 14.9999 9.40039 15C8.91365 15 8.50769 14.7665 8.19922 14.4258C7.89083 14.7661 7.48636 15 7 15C6.72386 15 6.5 14.7761 6.5 14.5C6.5 14.2239 6.72386 14 7 14C7.21245 14 7.51918 13.8199 7.74023 13.3037L7.77441 13.2373C7.86451 13.0913 8.02513 13 8.2002 13C8.40022 13.0001 8.58145 13.1198 8.66016 13.3037C8.88121 13.8198 9.18796 14 9.40039 14C9.61284 13.9998 9.9197 13.8197 10.1406 13.3037L10.1748 13.2373C10.2649 13.0915 10.4248 13.0001 10.5996 13C10.7997 13 10.9808 13.1198 11.0596 13.3037C11.2806 13.8198 11.5874 13.9999 11.7998 14C12.0122 14 12.319 13.8198 12.54 13.3037ZM12.54 9.30371C12.6486 9.05001 12.9425 8.93174 13.1963 9.04004C13.45 9.14863 13.5683 9.44253 13.46 9.69629C13.1651 10.3853 12.589 11 11.7998 11C11.3132 10.9999 10.908 10.7663 10.5996 10.4258C10.2913 10.7661 9.88667 10.9999 9.40039 11C8.91365 11 8.50769 10.7665 8.19922 10.4258C7.89083 10.7661 7.48636 11 7 11C6.72386 11 6.5 10.7761 6.5 10.5C6.5 10.2239 6.72386 10 7 10C7.21245 10 7.51918 9.8199 7.74023 9.30371L7.77441 9.2373C7.86451 9.09126 8.02513 9 8.2002 9C8.40022 9.00008 8.58145 9.11981 8.66016 9.30371C8.88121 9.8198 9.18796 10 9.40039 10C9.61284 9.99978 9.9197 9.81969 10.1406 9.30371L10.1748 9.2373C10.2649 9.09147 10.4248 9.00014 10.5996 9C10.7997 9 10.9808 9.11975 11.0596 9.30371C11.2806 9.8198 11.5874 9.99989 11.7998 10C12.0122 10 12.319 9.81985 12.54 9.30371ZM10 2.5C8.89543 2.5 8 3.39543 8 4.5V5H12V4.5C12 3.39543 11.1046 2.5 10 2.5Z"></path></svg></div><div class="flex items-center justify-center absolute top-0 left-0 transition-all opacity-0 scale-50" style="width: 20px; height: 20px;"><svg width="20" height="20" viewBox="0 0 20 20" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="shrink-0 absolute top-0 left-0 transition-all opacity-0 scale-50" aria-hidden="true"><path d="M15.1883 5.10908C15.3699 4.96398 15.6346 4.96153 15.8202 5.11592C16.0056 5.27067 16.0504 5.53125 15.9403 5.73605L15.8836 5.82003L8.38354 14.8202C8.29361 14.9279 8.16242 14.9925 8.02221 14.9989C7.88203 15.0051 7.74545 14.9526 7.64622 14.8534L4.14617 11.3533L4.08172 11.2752C3.95384 11.0811 3.97542 10.817 4.14617 10.6463C4.31693 10.4755 4.58105 10.4539 4.77509 10.5818L4.85321 10.6463L7.96556 13.7586L15.1161 5.1794L15.1883 5.10908Z"></path></svg></div></div></button></div></div><div><pre class="code-block__code !my-0 !rounded-lg !text-sm !leading-relaxed" style="background: transparent; color: rgb(171, 178, 191); text-shadow: rgba(0, 0, 0, 0.3) 0px 1px; font-family: var(--font-mono); direction: ltr; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; line-height: 1.5; tab-size: 2; hyphens: none; padding: 1em; margin: 0.5em 0px; overflow: auto; border-radius: 0.3em;"><code style="background: transparent; color: rgb(171, 178, 191); text-shadow: rgba(0, 0, 0, 0.3) 0px 1px; font-family: var(--font-mono); direction: ltr; text-align: left; white-space: pre-wrap; word-spacing: normal; word-break: normal; line-height: 1.5; tab-size: 2; hyphens: none;"><span><span>Здоровенная инструкция, написанная на человеческом языке,
</span></span><span>достаточно четко описывающая шаг за шагом, как должна думать
</span><span>нейросеть, как она должна выдавать свой ответ и куча всего еще.</span></code></pre></div></div>
    <p class="whitespace-normal break-words">Как вы видите, тут далеко не два слова, и не три слова, и даже не два абзаца. Тут здоровенная инструкция, написанная на человеческом языке, но достаточно четко описывающая шаг за шагом, как должна думать нейросеть, как она должна выдавать свой ответ и куча всего еще.</p>
    <p class="whitespace-normal break-words">Вот это и есть техники промпт-инжиниринга. И с таким промптом, например, Claude 3.5 Sonnet выдаст достаточно хороший ответ по программированию. Конкретно этот промпт можно найти по ссылочке на нашем гитхабе, на гитхабе нашего клуба. Он открыт. Я там собираю юзкейсы, которые мы в клубе находим с вами, и там юзкейс номер 10, это вот этот промпт для Sonnet 3.5. Я его использую, очень качественный.</p>
    <h3 class="text-lg font-bold text-text-100 mt-1 -mb-1.5">Ресурсы для изучения</h3>
    <p class="whitespace-normal break-words">Но если хотите узнать больше про техники промпт-инжиниринга, you are welcome в <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">promptingguide.ai</code> сайт. Мы еще в видосе, по-моему, с техникой уровня мастер будем чуть подробнее обсуждать, какие есть популярные техники промптинга, но если не терпится, то сходите на сайтик, почитайте. Там люди собирают все существующие полезные техники для написания промптов, для промпт-инжиниринга.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:06:16 - Токен (Token)</h2>
    <p class="whitespace-normal break-words">Что такое токен? Если кто-то из крипты пришел, то вы знаете, что токен там — это какая-то единица, которая по блокчейну туда-сюда гоняется. Здесь это тоже единица. Это минимальная единица информации, с которой работает модель. Можно сказать, что это слог в базовом словаре модели.</p>
    <p class="whitespace-normal break-words">Да, у модели есть словарь, по которому она разбивает пришедший ей на вход текст, если это классическая LLM-ка. Разбивает его на слоги, на токены. И токен может состоять из разных сущностей. Это может быть как один символ из алфавита, так и целое слово, или даже части так называемого токенизированного файла.</p>
    <p class="whitespace-normal break-words">Причем не обязательно текст. То есть если нейронка принимает на вход видео, аудио, изображение, то на токены разбиваются и эти форматы. Каждое семейство моделей определяет свой собственный набор токенов, а некоторые модели, полученные путем обучения базовой модели, определяют дополнительный слой токенов над базовым.</p>
    <h3 class="text-lg font-bold text-text-100 mt-1 -mb-1.5">Размер словаря и его влияние</h3>
    <p class="whitespace-normal break-words">И, как правило, больше словарь токенов обычно означает, что для представления заданного количества текста требуется меньше токенов. То есть, чем больше словарь, тем больше текста может поместиться в меньшее количество токенов. Концепция звучит сложно, но по факту токен — это вот эта вот единица информации, с которой моделька работает.</p>
    <p class="whitespace-normal break-words">И надо тут разве что знать, что для разных алфавитов, для разных кодировок это может работать по-разному. Например, еще там полтора года назад токен в русском языке — это был один символ, а токен в английском языке часто было слово или может даже что-то большее. Сейчас уже примерно одинаково в русском языке и в английском языке.</p>
    <h3 class="text-lg font-bold text-text-100 mt-1 -mb-1.5">Экономическая сторона</h3>
    <p class="whitespace-normal break-words">Что из этого следует? Из этого следует, например, то, что раньше на русском языке было дороже с сетями работать, потому что тупо сильно больше токенов тратилось при общении с ней. А экономика нейросетей, она считается по количеству сгенерированных токенов, забегая наперед немножко скажу.</p>
    <p class="whitespace-normal break-words">Поэтому вот, чем лучше, качественнее, больше словарь, тем больше текста можно меньшим количеством токенов выразить, а значит, тем быстрее и дешевле будет работать нейросеточка.</p>
    <h3 class="text-lg font-bold text-text-100 mt-1 -mb-1.5">Визуализация токенизации</h3>
    <p class="whitespace-normal break-words">Как-то вот так можно графически представить токенизированный абзац, который приходит на вход нейросети:</p>
    <div class="relative group/copy bg-bg-000/50 border-0.5 border-border-400 rounded-lg"><div class="sticky opacity-0 group-hover/copy:opacity-100 top-2 py-2 h-12 w-0 float-right"><div class="absolute right-0 h-8 px-2 items-center inline-flex z-10"><button class="inline-flex
  items-center
  justify-center
  relative
  shrink-0
  can-focus
  select-none
  disabled:pointer-events-none
  disabled:opacity-50
  disabled:shadow-none
  disabled:drop-shadow-none border-transparent
          transition
          font-base
          duration-300
          ease-[cubic-bezier(0.165,0.85,0.45,1)] h-8 w-8 rounded-md active:scale-95 backdrop-blur-md Button_ghost__Ywhj1" type="button" aria-label="Copy to clipboard" data-state="closed"><div class="relative"><div class="flex items-center justify-center transition-all opacity-100 scale-100" style="width: 20px; height: 20px;"><svg width="20" height="20" viewBox="0 0 20 20" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="shrink-0 transition-all opacity-100 scale-100" aria-hidden="true"><path d="M10 1.5C11.1097 1.5 12.0758 2.10424 12.5947 3H14.5C15.3284 3 16 3.67157 16 4.5V16.5C16 17.3284 15.3284 18 14.5 18H5.5C4.67157 18 4 17.3284 4 16.5V4.5C4 3.67157 4.67157 3 5.5 3H7.40527C7.92423 2.10424 8.89028 1.5 10 1.5ZM5.5 4C5.22386 4 5 4.22386 5 4.5V16.5C5 16.7761 5.22386 17 5.5 17H14.5C14.7761 17 15 16.7761 15 16.5V4.5C15 4.22386 14.7761 4 14.5 4H12.958C12.9853 4.16263 13 4.32961 13 4.5V5.5C13 5.77614 12.7761 6 12.5 6H7.5C7.22386 6 7 5.77614 7 5.5V4.5C7 4.32961 7.0147 4.16263 7.04199 4H5.5ZM12.54 13.3037C12.6486 13.05 12.9425 12.9317 13.1963 13.04C13.45 13.1486 13.5683 13.4425 13.46 13.6963C13.1651 14.3853 12.589 15 11.7998 15C11.3132 14.9999 10.908 14.7663 10.5996 14.4258C10.2913 14.7661 9.88667 14.9999 9.40039 15C8.91365 15 8.50769 14.7665 8.19922 14.4258C7.89083 14.7661 7.48636 15 7 15C6.72386 15 6.5 14.7761 6.5 14.5C6.5 14.2239 6.72386 14 7 14C7.21245 14 7.51918 13.8199 7.74023 13.3037L7.77441 13.2373C7.86451 13.0913 8.02513 13 8.2002 13C8.40022 13.0001 8.58145 13.1198 8.66016 13.3037C8.88121 13.8198 9.18796 14 9.40039 14C9.61284 13.9998 9.9197 13.8197 10.1406 13.3037L10.1748 13.2373C10.2649 13.0915 10.4248 13.0001 10.5996 13C10.7997 13 10.9808 13.1198 11.0596 13.3037C11.2806 13.8198 11.5874 13.9999 11.7998 14C12.0122 14 12.319 13.8198 12.54 13.3037ZM12.54 9.30371C12.6486 9.05001 12.9425 8.93174 13.1963 9.04004C13.45 9.14863 13.5683 9.44253 13.46 9.69629C13.1651 10.3853 12.589 11 11.7998 11C11.3132 10.9999 10.908 10.7663 10.5996 10.4258C10.2913 10.7661 9.88667 10.9999 9.40039 11C8.91365 11 8.50769 10.7665 8.19922 10.4258C7.89083 10.7661 7.48636 11 7 11C6.72386 11 6.5 10.7761 6.5 10.5C6.5 10.2239 6.72386 10 7 10C7.21245 10 7.51918 9.8199 7.74023 9.30371L7.77441 9.2373C7.86451 9.09126 8.02513 9 8.2002 9C8.40022 9.00008 8.58145 9.11981 8.66016 9.30371C8.88121 9.8198 9.18796 10 9.40039 10C9.61284 9.99978 9.9197 9.81969 10.1406 9.30371L10.1748 9.2373C10.2649 9.09147 10.4248 9.00014 10.5996 9C10.7997 9 10.9808 9.11975 11.0596 9.30371C11.2806 9.8198 11.5874 9.99989 11.7998 10C12.0122 10 12.319 9.81985 12.54 9.30371ZM10 2.5C8.89543 2.5 8 3.39543 8 4.5V5H12V4.5C12 3.39543 11.1046 2.5 10 2.5Z"></path></svg></div><div class="flex items-center justify-center absolute top-0 left-0 transition-all opacity-0 scale-50" style="width: 20px; height: 20px;"><svg width="20" height="20" viewBox="0 0 20 20" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="shrink-0 absolute top-0 left-0 transition-all opacity-0 scale-50" aria-hidden="true"><path d="M15.1883 5.10908C15.3699 4.96398 15.6346 4.96153 15.8202 5.11592C16.0056 5.27067 16.0504 5.53125 15.9403 5.73605L15.8836 5.82003L8.38354 14.8202C8.29361 14.9279 8.16242 14.9925 8.02221 14.9989C7.88203 15.0051 7.74545 14.9526 7.64622 14.8534L4.14617 11.3533L4.08172 11.2752C3.95384 11.0811 3.97542 10.817 4.14617 10.6463C4.31693 10.4755 4.58105 10.4539 4.77509 10.5818L4.85321 10.6463L7.96556 13.7586L15.1161 5.1794L15.1883 5.10908Z"></path></svg></div></div></button></div></div><div><pre class="code-block__code !my-0 !rounded-lg !text-sm !leading-relaxed" style="background: transparent; color: rgb(171, 178, 191); text-shadow: rgba(0, 0, 0, 0.3) 0px 1px; font-family: var(--font-mono); direction: ltr; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; line-height: 1.5; tab-size: 2; hyphens: none; padding: 1em; margin: 0.5em 0px; overflow: auto; border-radius: 0.3em;"><code style="background: transparent; color: rgb(171, 178, 191); text-shadow: rgba(0, 0, 0, 0.3) 0px 1px; font-family: var(--font-mono); direction: ltr; text-align: left; white-space: pre-wrap; word-spacing: normal; word-break: normal; line-height: 1.5; tab-size: 2; hyphens: none;"><span><span>[Графическое представление показывает, как текст разбивается
</span></span><span>на отдельные токены перед подачей в нейросеть]</span></code></pre></div></div>
    <h3 class="text-lg font-bold text-text-100 mt-1 -mb-1.5">Лекция Андрея Карпатова</h3>
    <p class="whitespace-normal break-words">И вот у Андрея Карпатова, которого я уже в предыдущем видео вспоминал, есть отличная часовая лекция, называется <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Let's Build the GPT Tokenizer</code>, в которой он показывает буквально за час на примерах, как строится токенайзер и как GPT, ранняя версия GPT, разбивает текст на токены.</p>
    <p class="whitespace-normal break-words">Так что, если хотите глубже разобраться, можете эту лекцию посмотреть, вместе с Андреем писать код, в принципе поймете, что такое токены и почему от их качества зависит скорость работы и стоимость работы модели.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:08:40 - Контекст (Context)</h2>
    <p class="whitespace-normal break-words">Третий термин по важности после промпта и токена — это контекст. Что такое контекст? Контекст — это совокупность информации, которая помогает модели лучше понять и интерпретировать данные.</p>
    <p class="whitespace-normal break-words">Контекстом обычно являются все предыдущие предложения, абзацы или более крупные фрагменты текста, иногда даже медиафайлы и документы отличные от текстовых файлов, которые были отправлены в LLM-ку в рамках сессии, где сессия — это, по факту, вот одна беседа. Вот когда мы нажимаем «Создать новый чат», это уже новая сессия.</p>
    <p class="whitespace-normal break-words">Оперируя информацией в контексте, LLM-ка более точно и эффективно отвечает на вопросы и выполняет задачи. И, кстати, базовым механизмом контекста является тот самый Attention, придуманный, по факту, Димой Богдановым и его корешами в 2014 году.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:09:29 - Размер контекста (Context Window)</h2>
    <p class="whitespace-normal break-words">Понятие размера контекста очень важно в работе с нейросетями. Размер контекста, либо <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">context-size</code>, либо <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">context-window</code>, либо окно контекста — это плюс-минус всё одно и то же. Это объём информации, который может быть рассмотрен моделью за один раз, и выражается он в токенах. Большее контекстное окно означает больше токенов, и, следовательно, больше текста может быть обработано за один раз моделью.</p>
    <h3 class="text-lg font-bold text-text-100 mt-1 -mb-1.5">Выход за рамки контекста (Out of Context)</h3>
    <p class="whitespace-normal break-words">Размер контекста модели обычно ограничен, а выход за рамки контекста часто приводит к так называемому галлюцинированию модели. И, собственно, выход за рамки контекста, либо <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">out of context</code>, — это ситуация, при которой общий размер диалога с моделью становится больше размера контекста.</p>
    <p class="whitespace-normal break-words">То есть, например, у нас количество контекста 100 токенов, а мы с ней наговорили суммарно — вот наше сообщение, плюс сообщение, которое именно она отвечала, плюс все, что мы отправляли, все вот в рамках сессии — занимает 110 токенов. То есть мы на 10 токенов уже вышли за рамки контекста.</p>
    <p class="whitespace-normal break-words">И при таком стечении обстоятельств новое сообщение, которое мы будем отправлять в модель, оно добавляется в контекст, а более старые куски начинают как бы забываться моделью. И алгоритм этого забывания зависит от архитектуры контекста. Он может полностью забываться, куски, которые вываливаются из контекста, могут резюмироваться другой сеточкой и подкидываться в текущий контекст.</p>
    <p class="whitespace-normal break-words">Есть разные реализации. Но в целом практически всегда выход за рамки контекста ведет к галлюцинированию.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:10:52 - Визуализация контекстного окна</h2>
    <p class="whitespace-normal break-words">Примерно вот так можно визуализировать контекстное окно. И тут, наверное, немножко порисую, покажу вам, как данные выходят за рамки контекста.</p>
    <p class="whitespace-normal break-words">Давайте отобразим наш контекст в LLM-ке таким прямоугольничком:</p>
    <div class="relative group/copy bg-bg-000/50 border-0.5 border-border-400 rounded-lg"><div class="sticky opacity-0 group-hover/copy:opacity-100 top-2 py-2 h-12 w-0 float-right"><div class="absolute right-0 h-8 px-2 items-center inline-flex z-10"><button class="inline-flex
  items-center
  justify-center
  relative
  shrink-0
  can-focus
  select-none
  disabled:pointer-events-none
  disabled:opacity-50
  disabled:shadow-none
  disabled:drop-shadow-none border-transparent
          transition
          font-base
          duration-300
          ease-[cubic-bezier(0.165,0.85,0.45,1)] h-8 w-8 rounded-md active:scale-95 backdrop-blur-md Button_ghost__Ywhj1" type="button" aria-label="Copy to clipboard" data-state="closed"><div class="relative"><div class="flex items-center justify-center transition-all opacity-100 scale-100" style="width: 20px; height: 20px;"><svg width="20" height="20" viewBox="0 0 20 20" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="shrink-0 transition-all opacity-100 scale-100" aria-hidden="true"><path d="M10 1.5C11.1097 1.5 12.0758 2.10424 12.5947 3H14.5C15.3284 3 16 3.67157 16 4.5V16.5C16 17.3284 15.3284 18 14.5 18H5.5C4.67157 18 4 17.3284 4 16.5V4.5C4 3.67157 4.67157 3 5.5 3H7.40527C7.92423 2.10424 8.89028 1.5 10 1.5ZM5.5 4C5.22386 4 5 4.22386 5 4.5V16.5C5 16.7761 5.22386 17 5.5 17H14.5C14.7761 17 15 16.7761 15 16.5V4.5C15 4.22386 14.7761 4 14.5 4H12.958C12.9853 4.16263 13 4.32961 13 4.5V5.5C13 5.77614 12.7761 6 12.5 6H7.5C7.22386 6 7 5.77614 7 5.5V4.5C7 4.32961 7.0147 4.16263 7.04199 4H5.5ZM12.54 13.3037C12.6486 13.05 12.9425 12.9317 13.1963 13.04C13.45 13.1486 13.5683 13.4425 13.46 13.6963C13.1651 14.3853 12.589 15 11.7998 15C11.3132 14.9999 10.908 14.7663 10.5996 14.4258C10.2913 14.7661 9.88667 14.9999 9.40039 15C8.91365 15 8.50769 14.7665 8.19922 14.4258C7.89083 14.7661 7.48636 15 7 15C6.72386 15 6.5 14.7761 6.5 14.5C6.5 14.2239 6.72386 14 7 14C7.21245 14 7.51918 13.8199 7.74023 13.3037L7.77441 13.2373C7.86451 13.0913 8.02513 13 8.2002 13C8.40022 13.0001 8.58145 13.1198 8.66016 13.3037C8.88121 13.8198 9.18796 14 9.40039 14C9.61284 13.9998 9.9197 13.8197 10.1406 13.3037L10.1748 13.2373C10.2649 13.0915 10.4248 13.0001 10.5996 13C10.7997 13 10.9808 13.1198 11.0596 13.3037C11.2806 13.8198 11.5874 13.9999 11.7998 14C12.0122 14 12.319 13.8198 12.54 13.3037ZM12.54 9.30371C12.6486 9.05001 12.9425 8.93174 13.1963 9.04004C13.45 9.14863 13.5683 9.44253 13.46 9.69629C13.1651 10.3853 12.589 11 11.7998 11C11.3132 10.9999 10.908 10.7663 10.5996 10.4258C10.2913 10.7661 9.88667 10.9999 9.40039 11C8.91365 11 8.50769 10.7665 8.19922 10.4258C7.89083 10.7661 7.48636 11 7 11C6.72386 11 6.5 10.7761 6.5 10.5C6.5 10.2239 6.72386 10 7 10C7.21245 10 7.51918 9.8199 7.74023 9.30371L7.77441 9.2373C7.86451 9.09126 8.02513 9 8.2002 9C8.40022 9.00008 8.58145 9.11981 8.66016 9.30371C8.88121 9.8198 9.18796 10 9.40039 10C9.61284 9.99978 9.9197 9.81969 10.1406 9.30371L10.1748 9.2373C10.2649 9.09147 10.4248 9.00014 10.5996 9C10.7997 9 10.9808 9.11975 11.0596 9.30371C11.2806 9.8198 11.5874 9.99989 11.7998 10C12.0122 10 12.319 9.81985 12.54 9.30371ZM10 2.5C8.89543 2.5 8 3.39543 8 4.5V5H12V4.5C12 3.39543 11.1046 2.5 10 2.5Z"></path></svg></div><div class="flex items-center justify-center absolute top-0 left-0 transition-all opacity-0 scale-50" style="width: 20px; height: 20px;"><svg width="20" height="20" viewBox="0 0 20 20" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="shrink-0 absolute top-0 left-0 transition-all opacity-0 scale-50" aria-hidden="true"><path d="M15.1883 5.10908C15.3699 4.96398 15.6346 4.96153 15.8202 5.11592C16.0056 5.27067 16.0504 5.53125 15.9403 5.73605L15.8836 5.82003L8.38354 14.8202C8.29361 14.9279 8.16242 14.9925 8.02221 14.9989C7.88203 15.0051 7.74545 14.9526 7.64622 14.8534L4.14617 11.3533L4.08172 11.2752C3.95384 11.0811 3.97542 10.817 4.14617 10.6463C4.31693 10.4755 4.58105 10.4539 4.77509 10.5818L4.85321 10.6463L7.96556 13.7586L15.1161 5.1794L15.1883 5.10908Z"></path></svg></div></div></button></div></div><div><pre class="code-block__code !my-0 !rounded-lg !text-sm !leading-relaxed" style="background: transparent; color: rgb(171, 178, 191); text-shadow: rgba(0, 0, 0, 0.3) 0px 1px; font-family: var(--font-mono); direction: ltr; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; line-height: 1.5; tab-size: 2; hyphens: none; padding: 1em; margin: 0.5em 0px; overflow: auto; border-radius: 0.3em;"><code style="background: transparent; color: rgb(171, 178, 191); text-shadow: rgba(0, 0, 0, 0.3) 0px 1px; font-family: var(--font-mono); direction: ltr; text-align: left; white-space: pre-wrap; word-spacing: normal; word-break: normal; line-height: 1.5; tab-size: 2; hyphens: none;"><span><span>┌─────────────────────────────────┐
</span></span><span>│     LLM.Context.Size            │
</span><span>│                                 │
</span><span>│  ┌──────────────────────────┐  │
</span><span>│  │ Prompt Input Tokens      │  │
</span><span>│  │ Count                    │  │
</span><span>│  └──────────────────────────┘  │
</span><span>│                                 │
</span><span>│  ┌──────────────────────────┐  │
</span><span>│  │ Generated Output Tokens  │  │
</span><span>│  │ Count                    │  │
</span><span>│  └──────────────────────────┘  │
</span><span>└─────────────────────────────────┘</span></code></pre></div></div>
    <h3 class="text-lg font-bold text-text-100 mt-1 -mb-1.5">Из чего состоит контекст</h3>
    <p class="whitespace-normal break-words">И главный вопрос для понимания того, как работает контекст — из чего, собственно, этот контекст в LLM-ке состоит. А состоит он, на самом деле, из двух частей.</p>
    <p class="whitespace-normal break-words">Первая часть — это то, что мы вводим в LLM-ку, то есть <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Prompt Input Tokens Count</code>, количество введенных в промптах токенов. Это могут быть промпты системные, пользовательские, разные, но все то, что попадает в LLM-ку.</p>
    <p class="whitespace-normal break-words">И кроме этого, контекст Size состоит, естественно, из того, что нам нагенерила в ответ LLM-ка, то есть это <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Generated Output Tokens Count</code>. Собственно, вот из этих двух частей состоит плюс-минус любой контекст LLM-очки. Весь тот диалог, который мы нагенерили в рамках беседы с LLM-кой.</p>
    <p class="whitespace-normal break-words">Соответственно, то, что мы ввели — Prompt Input Tokens Count, и то, что нам LLM-ка в ответ нагенерила, причем полностью все введенные, полностью все сейчас генерированные токены, это и есть размер контекста LLM-ки.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:12:19 - Примеры размеров контекста</h2>
    <p class="whitespace-normal break-words">Размер контекста, как говорил, измеряется в токенах, и на сегодняшний день средние размеры контекста примерно 1024 токена. Не помню, какой минимальный контекст может быть, наверняка там от нескольких токенов, но максимальное, что видел на сегодняшний момент, это 2 миллиона токенов — на данный момент доступны у Gemini 1.5 Pro. Это гугловская нейросеточка.</p></div></div>
  <div><div class="grid-cols-1 grid gap-2.5 [&amp;_&gt;_*]:min-w-0 !gap-3.5"><h1 class="text-2xl font-bold mt-1 text-text-100">Базовая терминология по AI: уровень "User" (продолжение)</h1>
    <p class="whitespace-normal break-words">00:12:47 --- Что важно понимать про токены? Во-первых, напоминаю, что токены отображают не букву, а слово, если мы говорим про английский язык. Да и русский алфавит тоже сейчас вмещается примерно в один токен. Плюс-минус у каждой LLM несколько символов, а может даже и целые слова. То, как текст разбивается на токены — это отдельная большая тема, этим занимаются специальные инструменты, которые называются токенизаторы. Про это подробно рассказывает Андрей Карпатый в своих видео, можете посмотреть, еще раз напоминаю.</p>
    <p class="whitespace-normal break-words">00:13:13 --- В целом просто важно понимать базовую вещь: токен не равен символу на сегодняшний день, даже с русским языком. Соответственно, если у нас есть контекст в 1024 токена, это обычно больше чем 1024 буквы. Для английского языка можно даже примерно аппроксимировать, что это приблизительно 1024 слова. Собственно, вот этот <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">context size</code>, размер контекста, он по факту состоит из всей истории переписки в рамках сессии с нашей нейросеточкой. Давайте теперь посмотрим, как этот контекст может заполняться и как он переполняется.</p>
    <p class="whitespace-normal break-words">00:13:44 --- Тут всё достаточно просто. Нарисуем такую ось, которую я вам уже показывал на предыдущей картинке. Где ноль — это ноль токенов, то есть это ось отправки токенов в нейронку, где ноль это начало, а конец — это много токенов. Та картинка, которую я вам показывал на предыдущем слайде, она статичная, и её минус в том, что на статике очень плохо можно отобразить то, как заполняется контекст у нейросеточки. Давайте попробуем это сделать здесь. У нас есть наш механизм контекста, он плавающий обычно. Что значит плавающий? Вот этот механизм контекста, обозначим его таким блоком, и по умолчанию, пока мы не начали в сессии ни с чем общаться, он стоит где-то там без дела, информации пока нет.</p>
    <p class="whitespace-normal break-words">00:14:35 --- Как только появляется какой-то первый промпт, который мы отправляем в нашу нейросеточку, обозначим его такой рисочкой, как только этот промпт появляется, наш контекст сразу же устремляется на эту информацию. Бах! И вот эта информация уже в контексте. Потом нейросеточка нам что-то ответила, и наш контекст, хоба, уже опять перемещается — он всегда смещается на пришедшую либо сгенерированную информацию. То есть он всегда, в обычную очередь по факту, кладёт себе все пришедшие промпты и все сгенерированные ответы. И таким образом при появлении всё новых промптов и новых ответов нейросети у нас контекст буквально с каждым новым промптом, с каждым новым ответом вот так вот постепенненько смещается, смещается, смещается.</p>
    <p class="whitespace-normal break-words">00:15:26 --- И в какой-то момент мы видим, что вот у нас самая новая информация вот здесь справа, наш контекст её в себя вобрал, а предыдущие промпты, предыдущие ответы, которые вышли за рамки контекста, они как бы в пролёте. Вот вся эта штука вышла за рамки контекста. Что с ней происходит? Происходит с ней разное, и, как я говорил, есть разные способы вот эту информацию брать и как-то обрабатывать через какие-нибудь специальные алгоритмы.</p>
    <p class="whitespace-normal break-words">00:15:58 --- Например, можно засаммаризировать эту информацию через ту же LLM. То есть взять информацию, которая вышла из контекста, сделать её краткое <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">summary</code>, сводку, и потом поместить в начало. Дорисовать сюда новый блок информации, который является засаммаризированной предыдущей информацией, и вот контекст перемещается, и вуаля — выпавшая из контекста информация снова появилась в контексте! Да, в сжатом виде, да, саммаризированная, но зато нейросеть не потеряла полностью те данные и ту информацию, про которую мы с ней общались. Есть разные способы подкидывания устаревших, вышедших из рамки контекста информации обратно в контекст, но главное это то, что контекст двигается — он двигается с самого начала до самого конца работы в рамках сессии, он двигается и смещается, и старая информация устаревает, выходит за рамки контекста.</p>
    <p class="whitespace-normal break-words">00:16:53 --- Интересно то, что контекст работает не совсем честно. То есть не вся информация, которая попадает в наш контекст, она на самом-то деле там доступна. Допустим, вот у нас есть здоровенный такой контекст — у того же Gemini, какого-нибудь, два миллиона токенов контекста. Здоровенный! Просто огромный — в два миллиона можно поместить большую-большую библиотеку, так-то.</p>
    <p class="whitespace-normal break-words">00:17:16 --- Вот у нас имеется этот двухмиллионный контекст. Мы размещаем, отправляем в LLM кучу-кучу разного текста. И с этой кучей информации, естественно, контекст будет работать по тем же правилам, по которым мы говорили. То есть вот он натравливается на самую последнюю информацию — кстати, это шкала ещё и временная, она направлена вправо, то есть новая информация появляется направее. Вот наш Gemini вот так вот двигался и двигался по мере появления информации, и вот он дошёл до самого обновлённого блока информации.</p>
    <p class="whitespace-normal break-words">00:17:47 --- Мы видим, что много информации уже из контекста вывалилось, как-то она там подкидывается снова в контекст, например, как я рассказывал минуту назад. Но фигня в чём? Фигня в том, что на больших контекстах работа с информацией вот отсюда и вот отсюда, из краёв контекста — то есть из краёв механизма обработки контекста — происходит сильно лучше, чем работа с информацией из центра.</p>
    <p class="whitespace-normal break-words">00:18:12 --- Это тоже одна из известных проблем. Почему-то механизмы обработки контекстов сильно лучше запоминают либо сильно лучше обрабатывают информацию по краям. А то, что в центре, оно часто вываливается. Есть даже тесты, когда в центр... загружают в Gemini, например, какую-нибудь здоровенную фантастическую библиотеку, а в центр вставляют какой-нибудь текст, который супер отличается от этой фантастической тематики. Например, вставляют туда рецепт драника.</p>
    <p class="whitespace-normal break-words">00:18:39 --- Всё, естественно, лежит в контексте. Это всё вписывается — два миллиона токенов контекста. И потом у Gemini спрашивают: расскажи мне рецепт драника. И Gemini ничего не может ответить! То есть он не видит в центре вот этот рецепт драника. Это важная информация — надо понимать, что не всё, что находится в контексте, будет стопроцентно обработано нейроночкой. Как это работает — это нужно отдельно разбираться с разными реализациями контекстов. Это сложная штука, которую я навряд ли расскажу. Посмотрите, может, Андрея Карпатого или ещё кого-то, если интересно.</p>
    <p class="whitespace-normal break-words">00:19:08 --- Но факт в том, что контекст работает по-разному с информацией в начале, в конце и в серединке. И, кстати, из-за этого есть забавный сайд-эффект. Если мы возьмём какой-нибудь другой механизм контекста — вот у нас тут механизм контекста от Gemini. Давайте возьмём механизм контекста от, например, GPT-4. У него, если я правильно помню, 128 тысяч токенов контекста.</p>
    <p class="whitespace-normal break-words">00:19:36 --- И он поменьше, то есть он получается сильно меньше. Тут пропорции неважны, не буду выдерживать пропорции. Основное, главное отличие в том, что он сильно меньше контекста Gemini. И если на одну и ту же информацию натравливаются два разных контекста, два разных механизма, две разных нейронки по факту — одна нейронка это Gemini, вторая нейронка это GPT-4 — оба механизма контекста вот так вот к самой свежей информации своим правым бочком подстраиваются, и что мы видим?</p>
    <p class="whitespace-normal break-words">00:20:02 --- То, что для Gemini на два миллиона токенов по факту левая сторона контекста является для GPT-4 всем контекстом! А у GPT-4 на 128 тысяч токенов он тоже те же самые проблемки имеет, что и работа с контекстом у того же Gemini. Работа с левым краем и с правым краем контекста хорошо происходит, а работа с центром оставляет желать лучшего.</p>
    <p class="whitespace-normal break-words">00:20:32 --- То есть GPT-4 будет с этой информацией работать сильно хуже, чем с информацией по краям. В то же время для Gemini на два миллиона токенов весь вот этот участок является левым краем, а значит, он будет работать с информацией из этого блока лучше, чем с ним будет работать GPT-4. Такая забавная штука.</p>
    <p class="whitespace-normal break-words">00:20:55 --- То есть, если объяснять простым языком: больший размер контекста у Gemini хорош не просто тем, что он сам по себе большой. Нет, у него есть проблемы, он будет плохо работать там по некоторым параметрам. Но сравнивая с меньшим контекстом, например GPT-4, контекстный механизм Gemini будет работать с той же самой информацией сильно лучше, потому что для Gemini весь объём текста, который помещается в GPT-4, является только там одним краюшком его механизма контекста — как раз таки тем краюшком, с которым он хорошо работает.</p>
    <p class="whitespace-normal break-words">00:21:25 --- Вот такой вот неочевидный нюанс. Попробовал объяснить. Не знаю, понятно или непонятно. Если непонятно, можете спросить в комментариях. Не можете, а спрашивайте в комментариях! Будем вместе разбираться. Собственно, галлюцинирование, либо <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">hallucination</code> на английском — что это такое? Это искажение информации в ответах модели. И кажется, что это одна из базовых характеристик современных генеративных нейросетей. Поэтому рекомендуется всегда проверять ответы генеративных моделей нейросетей на фактологическую точность.</p>
    <p class="whitespace-normal break-words">00:21:54 --- Какие могут быть причины галлюцинирования у LLM? Они могут быть на самом деле разные. Например, это может быть расхождение источника информации и ссылок на него — то есть информация просто не сходится, её надо как-то склеить, и нейросеть её склеивает. Это может быть эксплойт, который через специальные <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">jailbreak</code>-промпты занесён в эту модель — то есть специальными промптами дезинформация внесена. Это может быть опора на неполные или противоречивые наборы данных, некачественные данные, переобучение или отсутствие новизны данных — то есть данные долгое время не обновлялись и уже устарели.</p>
    <p class="whitespace-normal break-words">00:22:27 --- Это может быть предположение из-за нечётких или недостаточно детальных, плохих промптов. И, соответственно, типы галлюцинирования у LLM тоже могут быть разные. Это может быть противоречие в предложениях, это может быть противоречие в промптах, фактическое противоречие. Это может быть бессмысленный вообще вывод, когда сетка вам говорит, что красный — это фиолетовый, кит — это рыба.</p>
    <p class="whitespace-normal break-words">00:22:48 --- Это могут быть нерелевантные либо прям случайные галлюцинации. Куча разных галлюцинаций! Нет какой-то единственной причины, нет какого-то единого типа, не единой типизации галлюцинации. В смысле, единственного типа. То есть это спектр фактологически неверных либо в принципе неверных ответов, которые засоряют ответы. Очевидная лухта. Тоже может быть галлюцинирование.</p>
    <p class="whitespace-normal break-words">00:23:11 --- И в целом, это база. Галлюцинации есть в нейросетках всегда. Есть куча работ, которые пытаются устранить эти галлюцинации, но в целом галлюцинации устранить сложно. Тут можно провести параллель с человеком. Вы тоже навряд ли помните, что вы ели три дня назад на обед. Если вы очень постараетесь, то велика вероятность, что вы какие-то факты додумаете. С такой точки зрения можно сказать, что вы тоже как бы сгаллюцинировали. Ну вот, что-то похожее у LLM творится в их нейросетевых мозгах.</p>
    <p class="whitespace-normal break-words">00:23:41 --- И последний на сегодня термин будет созвучен с предыдущими терминами, но их касается очень посредственно. Это ограничение выходного контекста. Ещё это называют <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">output limit</code>, либо <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">output token limit</code>, либо <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">max tokens-to-sample</code> — в Claude это так называется. В общем, разные есть названия. По факту это объём информации, который может выдать модель в качестве ответа за один раз. То есть вот сколько моделька может вам токенов выдать в ответе на ваш вопрос? Не полностью в рамках всей сессии, а конкретно в одном ответе. С понятием контекст, описанным выше, эта штука имеет прям мало чего общего — разве что выходной контекст является частью общего контекста, частью общего диалога.</p>
    <p class="whitespace-normal break-words">00:24:15 --- Именно из-за того, что существует ограничение количества выходного контекста, именно поэтому, например, в чате GPT есть кнопка <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Continue</code>, продолжить. Когда он вам генерирует, генерирует, генерирует ответ большой, и потом запинается. И для того, чтобы ответ продолжился, в чате GPT надо нажать кнопочку <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Continue</code>. Например, в Claude либо в каких-нибудь open source LLM такой кнопки нет. Если нейросетка запинается на половине ответов, то знайте, что она просто вышла за рамки ограничения выходного контекста.</p>
    <p class="whitespace-normal break-words">00:24:40 --- Он может быть разный — там от тысячи токенов до шестнадцати тысяч токенов. И чтобы нейросетка просто продолжила ответ, достаточно написать <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">continue</code>, либо продолжай. И она ровненько с того места, где закончила, продолжит вам отвечать. Вот так вот выглядят ограничения выходного контекста.</p>
    <p class="whitespace-normal break-words">00:25:07 --- На этом терминология уровня User закончена. В следующий раз мы поговорим уже про подлиннее, про более сложную терминологию — терминологию уровня Pro. Эта терминология вам уже понадобится для того, чтобы настраивать нейросеточки у себя локально, для того, чтобы настраивать их на лучшую работу с программированием и всё такое. Так что встретимся в следующих видео, и пока-пока!</p></div></div>
</template>
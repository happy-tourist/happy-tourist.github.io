<template>
  <div><div class="grid-cols-1 grid gap-2.5 [&amp;_&gt;_*]:min-w-0 !gap-3.5"><h1 class="text-2xl font-bold mt-1 text-text-100">Пересказ: Базовая терминология по AI - уровень Master</h1>
    <p class="whitespace-normal break-words"><strong>00:00:05</strong> --- Всем привет! Это четвертое видео из серии базовой терминологии по искусственному интеллекту. Сегодня будем изучать уровень Master - и это самый сложный уровень из всех. Сразу честно признаюсь: далеко не всё, о чем буду рассказывать, знаю с практической точки зрения. С чем-то знакомился исключительно по описаниям и документации. Но думаю, информация всё равно будет полезной. Если захотите больше деталей и ссылок, в описании к ролику есть файлик с базовой терминологией - открываете его, и там можно найти дополнительную информацию, по которой я ровненько иду.</p>
    <p class="whitespace-normal break-words"><strong>00:00:44</strong> --- Терминология уровня Master пригодится вам, если захотите еще глубже погрузиться в мир <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">LLM</code> - уже на уровень имплементации их в собственных приложениях, а может даже на уровень тренировки моделей и вот всего, что связано непосредственно с ковырянием в моделях. Если не видели предыдущие ролики с терминологией уровней Newbie, User и Pro, то обязательно их посмотрите, потому что термины оттуда будут сегодня использоваться - идем по нарастающей.</p>
    <p class="whitespace-normal break-words"><strong>00:01:10</strong> --- Начнем с популярного инструментария, который пригодится при разработке приложений с <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">LLM</code>. Самое первое - это векторная база данных. Это особый тип хранилищ, который специально создан для хранения многомерных векторов и эмбеддингов. Каждый вектор представляет собой численную интерпретацию какого-либо типа данных - это может быть текст, аудио, видео и другие типы данных. Про это подробнее говорили в терминологии уровня Pro, когда обсуждали эмбеддинги и вспоминали, что такое векторы из математики. Такие базы данных отлично подходят для семантического поиска, для поиска ближайших соседей, для работы с эмбеддинг-матрицами, поиска по смыслу, рекомендаций, кластеризации и прочих популярных задач в мире машинного обучения. Примерами таких баз являются <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Pinecone</code>, <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Weaviate</code>, <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Chroma</code> - и их много всяких других на рынке, можете просто загуглить.</p>
    <p class="whitespace-normal break-words"><strong>00:01:59</strong> --- Следующий инструмент уже известен тем из вас, кто внимательно следит за воркшопами - это <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Jupyter Notebook</code>. Про него у нас был воркшоп, ссылочка будет в описании. По сути это веб-IDE, разработанная специально для работы с так называемыми ноутбуками - это такие файлы с расширением <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">.ipynb</code>, в которых можно писать блоки кода, ячейки кода, и выполнять каждую ячейку независимо друг от друга. Каждая ячейка может визуализировать свой результат текстом либо графиками, а также в этих файлах можно удобно делать описание каждой из ячеек через хорошо нам известную разметку <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Markdown</code>. Ноутбуки широко используются специалистами Data Science, ребятами, которые ставят эксперименты с моделями, и программистами, которые работают с моделями. Это удобный формат работы с моделями, с их обучением и с передачей данных и экспериментов другим сотрудникам, чтобы они тоже там могли что-то поделать и сделать свои выводы. <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Jupyter Notebook</code> настолько стал популярным форматом, что в популярных IDE типа <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Visual Studio Code</code> уже есть нативная поддержка файлов с этим расширением - более того, функционал по работе с ноутбуками в IDE даже сильно шире, чем в веб-версии. Поэтому прямо сейчас можете попробовать, что это такое - просто создайте файлик с расширением <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">.ipynb</code>, и вы увидите интерфейс работы. Ну а лучше всего, конечно же, посмотреть воркшоп по работе с ноутбуками.</p>
    <p class="whitespace-normal break-words"><strong>00:03:32</strong> --- Следующий инструмент - это целый веб-сайт, на который вы наверняка наталкивались в процессе работы с <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">LLM</code>. Это <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Hugging Face</code> - французская компания, которая де-факто является таким GitHub'ом в мире дата-сайентистов и людей, работающих с моделями. На этом сайте хранятся просто сотни тысяч - это действительно так - сотни тысяч датасетов и сотни тысяч разнообразных моделей. Пользователи могут сами загружать туда модели, единственное - надо платить за место. Компании загружают туда модели, и все к ним могут получить доступ и использовать. Также в <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Hugging Face</code> есть так называемые Spaces - это пространства, в которых можно запускать модели самим, либо компании выкатывают демки своих моделей в этих Spaces. Поэтому <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Hugging Face</code> - это значимая инфраструктура для всех, кто работает с <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">LLM</code> и другими моделями, не только с <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">LLM</code>. Надо знать про этот инструмент обязательно. Тут стоит сказать, что есть аналоги - из крупных, наверное, можно упомянуть про <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Model Scope</code>. Это китайский аналог <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Hugging Face</code>, где китайские модели в основном выходят в первую очередь.</p>
    <p class="whitespace-normal break-words"><strong>00:04:35</strong> --- Следующий инструмент - это библиотека <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Pandas</code>. Она служит для удобства обработки данных, которые можно потом использовать для тренировки моделей. Работает с табличными данными, упрощает очистку данных, их трансформацию, помогая делать хороший и устоявшийся на рынке набор инструментов для работы с данными. Построена библиотека поверх библиотеки <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">NumPy</code>, про которую чуть дальше расскажу. Еще есть отдельный класс библиотек, которые созданы для того, чтобы визуализировать данные в рамках экспериментов - например, в том же <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Jupyter Notebook</code> их можно использовать. Это <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Matplotlib</code>, это <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Seaborn</code>, это <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Plotly</code> и другие инструменты. Про некоторые из них, кстати, тоже говорили в воркшопе про <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Jupyter Notebook</code> - можете глянуть, как это выглядит по факту. Эти библиотеки позволяют удобным образом визуализировать те данные, с которыми работаем в рамках обучения моделей, тренировки моделей - ну и просто визуализировать данные. Достаточно удобная штука! И не только графиками ограничивается интерактивность работы с ними - <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Plotly</code>, например, может выстраивать целые дашборды прямо в <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Jupyter Notebook</code> и позволяет еще более удобно работать с данными.</p>
    <p class="whitespace-normal break-words"><strong>00:05:31</strong> --- Следующий класс библиотек и программ используется для того, чтобы помогать в экспериментах, которые проводятся с моделями. Это <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">MLflow</code>, это <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Weights and Biases</code>, и, например, это <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Neptune</code>. Есть и другие, конечно же, инструменты, но эти чаще всего используются. Они помогают трекать эксперименты, модели, параметры - в общем, всячески помогают более качественно работать с экспериментами и сравнивать результаты экспериментов на одних и тех же или на разных моделях. Это часто нужно для того, чтобы сравнить, какая модель лучше либо хуже работает на конкретной задаче. В воркшопе по <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Jupyter Notebook</code> в комментариях спрашивали, есть ли инструменты отдельные для контроля версий кода, которые пишем в <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Jupyter Notebook</code>. И да, такие системы есть - например, посмотрите на <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Data Version Control</code>. Эта штука позволяет удобно контролировать версии, версионировать код, контролировать изменения данных по ходу эксперимента. Да, тут много говорю про эксперименты - опять-таки, те, кто смотрели воркшоп по Jupyter Notebook, уже понимают, что это такое. Эксперимент - это в целом флоу работы с моделью с какой-то целью. Например, надо файн-тюнить новую модель и посмотреть, насколько она хорошо стала либо плохо работать с экспериментальной выборкой данных. Весь код, который это всё дело делает - это и будет суть эксперимента. Это можно назвать экспериментом в данном случае. Поэтому не удивляйтесь, не пугайтесь - это не какой-то там научный эксперимент типа испытания на адронном коллайдере. Всё сильно проще.</p>
    <p class="whitespace-normal break-words"><strong>00:06:50</strong> --- Так как сейчас говорим про инструментарий, которым пользуются дата-сайентисты, а дата-сайентисты часто не профессиональные программисты в широком понимании - то есть они не пишут веб-приложения - то им нужны инструменты, которые позволяют быстро подключить модель и визуализировать то, как она работает, например, для заказчика. Сделать красивенькую формочку, красивенький сайт, на котором всё красиво с графиками будет выводиться. Для этого тоже есть готовые инструменты - например, <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Streamlit</code>, <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Gradio</code>. С <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Gradio</code>, думаю, кто-то из вас знаком. Они как раз для этого служат. Ну и куда ж в эксперименте без хорошо настроенного пайплайна работы с моделью! И да, тут используются <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Kubernetes</code> и <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Docker</code> - хорошо нам знакомые - но есть надстройки над ними, например, <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Kubeflow</code>, <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Airflow</code>. Это всё специализированные надстройки, которые помогают работать именно с Machine Learning пайплайнами для того, чтобы обучить модель, валидировать её, задеплоить её и дальше мониторить. И всё это в одном настроенном пайплайне, который не надо потом постоянно переписывать и перезапускать вручную. Для этого есть инструменты, вот такие - ими тоже часто пользуются, и вам они могут пригодиться при настройке либо работе с какими-нибудь моделями.</p>
    <p class="whitespace-normal break-words"><strong>00:07:49</strong> --- Ну и последний класс приложений, который может пригодиться - это приложения, которые помогают размечать данные. Потому что когда обучаем модели, часто нужно датасет либо подправить, либо вообще с нуля собрать, и данные нужно как-то размечать. Для этого есть Labeling Tools, инструменты для разметки - <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Label Studio</code>, <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">CVAT</code> и другие инструменты помогают это делать. Там тоже всё нормально, не надо придумывать никакие велосипеды - всё уже придумано.</p>
    <p class="whitespace-normal break-words"><strong>00:08:43</strong> --- Едем дальше. Для того чтобы понимать, как правильно работать с конкретной моделью, было бы неплохо знать базовые фреймворки, с помощью которых эти модели были построены, потому что чаще всего с помощью этих фреймворков они и запускаются. Тут традиционно начинаем с самого, наверное, популярного - это <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">TensorFlow</code>. Про него вы наверняка слышали. Это фреймворк от Google, написанный на <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">C++</code> и разработанный специально для запуска моделей машинного обучения и глубокого обучения - запуск, инференс и обучение. Для этого нужен <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">TensorFlow</code>. Да, там еще кроме <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">C++</code> и <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Python</code> есть, но в целом <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">TensorFlow</code> - очень шустрый фреймворк, это одна из его фишек. И есть его адаптации: <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">TensorFlow Lite</code> для мобильных устройств и <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">TensorFlow.js</code>, соответственно, для того, чтобы можно было веб-модели запускать и обучать.</p>
    <p class="whitespace-normal break-words"><strong>00:09:06</strong> --- Второй по популярности на сегодняшний день фреймворк - это, правильно, <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">PyTorch</code>. Он разработан командой Facebook, нынешней Meta, и сделан с суперудобным по сравнению с <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">TensorFlow</code> интерфейсом. Достаточно гибкий и хорош для прототипирования - то есть эта штука сильно более удобная, по крайней мере, это то, что рассказывали ребята, которые с ним работают, но не такая шустрая, как <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">TensorFlow</code> - чем-то жертвовать надо было. Изначально <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">PyTorch</code> был распространен среди исследователей, но сейчас он успешно используется в том числе и в продакшене - на нем можно легко прототипировать что-нибудь и потом катануть в прод. То есть в целом он не настолько тупой, чтобы его вообще не использовать - всё там нормально. Просто по сравнению с <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">TensorFlow</code>, конечно, <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">PyTorch</code> помедленнее будет, но и то, и то используется, и то, и то очень популярно в среде разработчиков моделей.</p>
    <p class="whitespace-normal break-words"><strong>00:10:01</strong> --- Дальше несколько библиотек, которые помогают делать сами модели. Это <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">NumPy</code> - это вообще базовая библиотека, в которой есть практически все базовые математические операции, которые можно делать над векторами и матрицами. Используется везде, суперудобная, суперраспространенная и, конечно же, супербыстрая. <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Keras</code> - это высокоуровневая Python-библиотека, позволяющая строить модели нейросетей из готовых компонентов слоев. Раньше она работала поверх <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">TensorFlow</code> и других менее популярных фреймворков, но сейчас она продолжает работать над <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">TensorFlow</code> и поддерживает другие популярные фреймворки - да, <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">PyTorch</code> и <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">JAX</code>, про которые сейчас расскажу. <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">JAX</code> - это фреймворк от Google, который создан для численных вычислений в машинном обучении. Использует под капотом так называемый автоград - это механизм автоматического дифференцирования, немножко математики - а также XLA-компилятор для ускорения вычислений на графических процессорах и тензорных процессорах, на которых сейчас нейронки запускают. Ну, тензор, матрица - всё про одно, поэтому тензорные процессоры - это крутая штука, пусть пока и не распространенная.</p></div></div>
  <div><div class="grid-cols-1 grid gap-2.5 [&amp;_&gt;_*]:min-w-0 !gap-3.5"><h1 class="text-2xl font-bold mt-1 text-text-100">Базовая терминология по AI: уровень "Master" (Продолжение)</h1>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:11:07</h2>
    <p class="whitespace-normal break-words"><code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">JAX</code> используется в исследованиях также для разработки генеративных моделей, благодаря своей быстрой работе и удобным абстракциям. Есть тут еще такая штука, как <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Flux</code>. Это не то, что вы слышали в JavaScript. Это высокоуровневая библиотека для <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">JAX</code>, которая упрощает построение архитектур нейросетей, их обучение и оптимизацию. Ну, то есть, просто предоставление удобных абстракций, что сильно ускоряет разработку.</p>
    <p class="whitespace-normal break-words">Open Neural Network Exchange Runtime, он же <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">ONNX Runtime</code>. Это кросс-платформенный движок для инференса и для ускорения обучения модели, причем поддерживает он модели, построенные на базе разных фреймворков. Это и <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">PyTorch</code>, и <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">TensorFlow</code>, и <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Keras</code>, и другие. Создан и разрабатывается этот движок компанией <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Microsoft</code>, запускается на разных операционных системах и сильно упрощает работу по перемещению, по масштабируемости моделей, написанных на разных фреймворках.</p>
    <p class="whitespace-normal break-words"><code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Transformers</code> — это, да, понятно, есть трансформеры, про которые мы уже с вами говорили, но также <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Transformers</code> — это популярная библиотека на <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Python</code>, написанная от <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Hugging Face</code>.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:12:11</h2>
    <p class="whitespace-normal break-words">И, собственно, эта библиотека позволяет работать с широким спектром разных моделей, написанных на разных фреймворках. Это и <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">PyTorch</code>, это <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">TensorFlow</code>, это <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">JAX</code>. И с помощью <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Transformers</code> модели можно инференсить, а также их можно дообучать. Кроме того, есть тесная интеграция с <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Hugging Face</code> и через <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Transformers</code> можно использовать разные токенизаторы, утилиты, в общем, удобная штука от компании, которая знает, как такие вещи делать.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:12:38</h2>
    <p class="whitespace-normal break-words">Его JavaScript-овая реализация под названием <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">TransformerJS</code> имеет чуть более урезанный функционал. Она может только запускать модели, но зато она может это делать прямо в браузере, используя <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">WASM</code>, а также используя <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">ONNX Runtime</code> либо <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">WebGPU</code>. Благодаря <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">TransformerJS</code> и запускаются все модели в браузерах. Вот то, что <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Chrome</code> нам показывал, это работает с помощью <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">TransformerJS</code>, если я правильно помню.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:13:02</h2>
    <p class="whitespace-normal break-words">Есть еще популярный фреймворк от <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Apache</code>, <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">MXNet</code>, и он крут тем, что поддерживает кучу языков программирования, разные парадигмы программирования и позволяет работать с ML, при этом хорошо масштабируя свои решения и эффективно работая в распределенных средах на разных технологиях.</p>
    <p class="whitespace-normal break-words"><code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">PaddlePaddle</code>, либо Parallel Distributed Deep Learning. Это фреймворк от компании <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Baidu</code>, который позволяет делать модели и обучать их. Преимущественно используется в китайских моделях и имеет сильную интеграцию с сервисами от <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Baidu</code>.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:13:35</h2>
    <p class="whitespace-normal break-words">Также есть интересный фреймворк от компании <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Huawei</code>, <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">MindSpore</code>. И у него упор на облачные и мобильные устройства, а также защиту данных. Так называемая концепция AI for All. Фреймворк предлагает инструменты для распределенного обучения, а также для работы на широком спектре устройств.</p>
    <p class="whitespace-normal break-words">Также был такой интересный фреймворк, разрабатывавшийся университетом Монреаля, назывался он <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Theano</code>. Внес немалый вклад в индустрию и вроде как потихоньку отмирает, уступив место более современным фреймворкам. У них прямо в репозитории написано, что теперь они работают над <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">PyTensor</code>.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:14:00</h2>
    <p class="whitespace-normal break-words">Вообще говоря, фреймворков куда больше, менее популярных, их просто тьма, про них вы можете почитать, но, думаю, тех, которые я вам перечислил только что, будет достаточно, чтобы работать плюс-минус с абсолютно любой архитектурой, любой моделью.</p>
    <p class="whitespace-normal break-words">Теперь давайте поговорим про форматы модели.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:14:26</h2>
    <p class="whitespace-normal break-words">Формат модели зависит от того, как она будет храниться, распространяться и запускаться, диктуется рантаймом, на котором будет запущен инференс этой модели. То есть, по факту, это про сериализацию данных. Например, модели, сделанные с помощью фреймворка <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">PyTorch</code>, после сериализации будут иметь расширение <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">.pt</code> либо <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">.pth</code>, и сериализуются эти модели по-разному.</p>
    <p class="whitespace-normal break-words">Например, есть такой сериализатор популярный, как <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Python Pickle</code>, который сериализует модели, но таким хитрым образом, что там остается место для имплементации, исполнения кастомного кода.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:14:57</h2>
    <p class="whitespace-normal break-words">То есть, грубо говоря, <strong>при загрузке модели от неизвестного вам автора у вас может запуститься какой-то произвольный <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Python</code>-код</strong>, что в какой-то момент стало опасным, поняли, что через этот код можно всячески плохие вещи делать, поэтому <strong>очень рекомендую вам обращать внимание, откуда вы скачиваете модели</strong>, и желательно пользоваться теми моделями, которые сериализованы вот без применения <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Python Pickle</code>, и не содержат тот код, который запустится, а вы об этом даже не знали.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:15:24</h2>
    <p class="whitespace-normal break-words">Ну и, собственно, проблему с запуском произвольного кода при запуске модели достаточно быстро решили, ввели такой формат, который называется <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">TorchScript</code>. Модель формата <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">TorchScript</code> может быть запущена и выполнена без доступа к исходному <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Python</code>-коду, что безопаснее, чем классические <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">PyTorch</code>-чекпоинты.</p>
    <p class="whitespace-normal break-words">Это такие файлы, в которых сохраняется состояние модели в процессе обучения, а также оптимизаторы, которые там использовались, и другие данные, и сделаны они для того, чтобы можно было продолжить процесс обучения с той точки, с того чекпоинта, на который он был остановлен. Не надо запускать процесс каждый раз заново, где остановился, оттуда и продолжил.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:15:56</h2>
    <p class="whitespace-normal break-words">Сейчас набирает популярность формат <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">SafeTensor</code>, который, в отличие от <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Python</code>-чекпоинтов, не хранит исполняемый код и не запускает его при запуске модели, а хранит только веса и метаданные. Ну и еще в нем есть <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">MemoryMapped</code> файлы, так называемые, которые существенно ускоряют запуск моделей на фоне других форматов.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:16:18</h2>
    <p class="whitespace-normal break-words">Еще к форматам частенько относят трансформеры от <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Hugging Face</code>. Ну, как мы уже сказали, трансформеры это все-таки фреймворк, а на <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Hugging Face</code> скорее важна архитектура хранения файлов, которые потом в трансформерах можно использовать.</p>
    <p class="whitespace-normal break-words">То есть там есть определенная структура файлов, туда определенным образом кладутся веса под конкретный фреймворк, будь то <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">PyTorch</code>, либо <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">TensorFlow</code>, там есть токенизаторы и набор некоторых других файлов, которые после скачки себе локально, либо в space при копировании, позволяют библиотеке <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Transformers</code> запускать эту модель без каких-то особых проблем.</p>
    <p class="whitespace-normal break-words">Ну и таким образом, <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Hugging Face</code> и <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Transformers</code> вместе упрощают интеграцию новых моделей, а также конвертацию, например, из <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">ONNX</code> в <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">TensorFlow</code> модельки.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:16:53</h2>
    <p class="whitespace-normal break-words">Формат <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">GGUF</code>, G-G-U-F, GPT Generated Unified Format. Он вам наверняка известен, потому что это тот формат, который используется в <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">LlamaStudio</code> и в <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">LlamaCPP</code>. Это инференция популярная, про которую я, кстати, видосы снимал, как минимум, про <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">LlamaStudio</code>, ссылка будет в описании.</p>
    <p class="whitespace-normal break-words">Собственно, формат этот сделан командой <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">llama-cpp</code> и специально сделан для того, чтобы модели можно было запускать на центральных процессорах, на <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">CPU</code>. Поскольку не у всех пользователей есть мощные графические карты для запуска моделей, но процессоры мощные много у кого есть. В макбуках, например, или еще где-нибудь.</p>
    <p class="whitespace-normal break-words">Поэтому гувки, наша с вами все, тех ребят, которые быстро тестят модели без вникновения в какие-то детали. В общем, формат должен быть нам уже знакомым. Но как видите, он отличается от всего остального, заточен под запуск на широком спектре устройств благодаря работе на <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">CPU</code>.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:17:47</h2>
    <p class="whitespace-normal break-words">Есть еще формат схожий, называется <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">GGML</code>, но он считается устаревшим и <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">GGUF</code> это его преемник, прямо идущие, прямой, прямой преемник.</p>
    <p class="whitespace-normal break-words">Есть еще <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">JAX</code>, это и формат, и набор инструментов, который позволяет работать с моделями, построенными в угловом фреймворком <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">JAX</code>, про которые чуть ранее говорил. Обычно веса для модели <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">JAX</code> представлены в виде совместимым с <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Flux</code>, ну и хранятся в формате <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">NumPy</code> массивов, либо бинарных сериализованных данных. Ну и конечно <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Google</code> частенько выпускает модели в формате <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">JAX</code>, их же фреймворк.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:18:16</h2>
    <p class="whitespace-normal break-words">Ну и раз есть <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">ONNX Runtime</code>, значит и есть их формат, он называется <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">ONNX</code>, он открытый, он позволяет запускать разные модели <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Keras</code>, <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">TensorFlow</code>, <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">PyTorch</code>, и, собственно, работает на разных процессорах, и на <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">CPU</code>, и на <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">GPU</code>, и на тензорных процессорах, чем, собственно, помогает переносить модели между разными инфраструктурами. Такой открытый, в каком-то смысле, кроссплатформенный формат и фреймворк.</p>
    <p class="whitespace-normal break-words">Едем дальше.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:19:09</h2>
    <p class="whitespace-normal break-words">Теперь надо поговорить про популярные концепции, про которые вы наверняка слышали, и которые вы будете тем чаще слышать, чем более плотнее станете работать с <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">LLM</code>-ками в рамках ваших приложений.</p>
    <p class="whitespace-normal break-words"><strong>Первое и самое важное</strong>, как по мне, это <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">RAG</code> — <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Retrieval Augmented Generation</code>. Если кратко, это метод, который улучшает качество ответов наших <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">LLM</code>. И делает он это достаточно просто, на первый взгляд. Он просто интегрирует данные из разных источников данных. Это могут быть и векторные базы, и результаты поиска, и все, что угодно. Картовые данные из Google Maps. Подмешивает их в результат, в ответ от <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">LLM</code>.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:19:35</h2>
    <p class="whitespace-normal break-words">То есть при работе вместе с <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">RAG</code>'ом <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">LLM</code> полагается не только на свои механизмы предсказания токенов, но также на ту информацию, которую вот этот <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">RAG</code>-механизм помог ей найти, которым он обогатил ее ответ.</p>
    <p class="whitespace-normal break-words">Часто <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">RAG</code>'и работают именно с векторными базами, потому что там есть эмбэйдинги. С помощью эмбэйдингов легко находить соответствие между запросом и тем, что лежит в базе данных, и механизм <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">RAG</code>'а выдает эти данные в ответе, а дальше <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">LLM</code>'ка уже сама подмешивает их в финальный ответ.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:20:02</h2>
    <p class="whitespace-normal break-words"><code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">RAG</code>'и есть суперразные, их куча разных реализаций. Вы можете посмотреть, например, реализацию на канале «Инструменты» просто по хэштегу «раг», вы найдёте, я думаю, из десяток добрых разных рагов.</p>
    <p class="whitespace-normal break-words">И надо сказать, что качество работы сегодняшних ассистентов для программирования в том же <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Cursor</code>, в <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">Cline</code>, в Windsurf, оно отличается во многом от имплементации рага под капотом. Потому что именно <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">RAG</code> отвечает в том числе и за понимание контекста этими ассистентами, контекста нашего проекта, нашего кода. Поэтому очень важная концепция.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:20:27</h2>
    <p class="whitespace-normal break-words">И иногда люди, кстати, думают, что файн-тюнинг моделей и <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">RAG</code> — это нечто похожее, потому что вроде и то, и то про новые знания в модели. Но на самом деле файн-тюнинг — это скорее больше про стилизацию ответов модели. Ну, либо если мы уже запускаем полное переобучение на здоровом количестве данных, то, конечно, это про новые данные в модели, но так мы с вами не делаем, это дорого и сложно.</p>
    <p class="whitespace-normal break-words">А вот <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">RAG</code> — это конкретно про обогащение ответов новыми данными. Но эти данные новые не впекаются в модель, они поднимаются из каких-то сторонних источников данных. И в этом огромная разница.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:20:54</h2>
    <p class="whitespace-normal break-words">И поэтому <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">RAG</code> используют повсеместно. <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">RAG</code> не портит работоспособность модели, поскольку он на нее никак напрямую не влияет, не изменяет ее весов. И используется для получения всяческих данных, которыми модель не владеет.</p>
    <p class="whitespace-normal break-words">Например, <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">RAG</code> хорошо используется для подмешивания в ответ свежих новостных данных, которых в модели наверняка нет. Именно так работает какой-нибудь сёрч в <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">GPT</code>, я думаю.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:21:26</h2>
    <p class="whitespace-normal break-words"><code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">RAG</code> тесно переплетён с концепцией агенты. И это не те агенты, которые были в матрице, это не люди, это не что-то суперсложное. По факту, агент — это программа, может быть, консоленная какая-нибудь, просто обычная программа, которая под капотом использует модель, например, <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">LLM</code>-ку, и обрабатывает конкретный участок общения с этой <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">LLM</code>-кой, собственно, достигая целей.</p>
    <p class="whitespace-normal break-words">То есть это такой коннектор между <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">LLM</code>-кой и каким-то, например, инструментом. Это вся сущность агентов.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:21:55</h2>
    <p class="whitespace-normal break-words">Могут быть разные агенты. Может быть, агент, который вызывает тулзы, инструменты. Может быть, агент, который ходит в поиск и возвращает ответы. Может быть, <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">RAG</code>-агент, который с рагом работает. Может быть, просто агент, который сохраняет наши запросы в базу данных. Может быть, агент, который подмешивает в наш запрос какой-нибудь дополнительный промпт, дополнительную настройку над промптом, и, не знаю, например, делит наш таск на подзадачи.</p>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">00:22:23</h2>
    <p class="whitespace-normal break-words">То есть пользователь шлет какую-нибудь цель, например, хочу написать веб-сайт по таким-то параметрам. Этот промпт сначала уходит в агент. Агент обогащает этот промпт, например, чем-нибудь типа «А ну-ка, разбей вот то, что будет дальше на подзадачи». Отправляет это в <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">LLM</code>, <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">LLM</code> возвращает этому агенту ответ. Уже с разбитыми подзадачами этот агент их парсит.</p>
    <p class="whitespace-normal break-words">Возвращает эти данные, например, другому агенту, который сохраняет их базу данных по задачам. Вот у нас уже в базе данных лежит несколько задач. Дальше агент, который разбирает очередь задач, берет по одной задачке, отправляет опять в какую-нибудь <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">LLM</code>-ку, может быть, вообще другую, <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">LLM</code>-ка эту задачу решает, он ее принимает, и, например, блоками по каждой задаче пишет нам веб-страницу.</p>
    <p class="whitespace-normal break-words">То есть в данной системе аж целых три агента.</p></div></div>
  <div><div class="grid-cols-1 grid gap-2.5 [&amp;_&gt;_*]:min-w-0 !gap-3.5"><h1 class="text-2xl font-bold mt-1 text-text-100">Базовая терминология по AI: уровень "Master"</h1>
    <h2 class="text-xl font-bold text-text-100 mt-1 -mb-0.5">Продолжение</h2>
    <p class="whitespace-normal break-words"><strong>00:23:12</strong> --- Итак, представьте себе систему из трёх агентов, работающих вместе. Первый агент разбивает задачу на подзадачи и общается между пользователем и какой-то одной LLM. Второй агент сохраняет эти подзадачи и ответ от первого агента в базу данных. А третий агент — это тот, который разбирает очередь в этой базе данных и генерирует финальное представление страницы. Может быть, звучит сложно, но вообще-то выведу картинку, как это выглядит. В принципе, это просто. Агенты — это обычные подпрограммы, программы, которые помогают воспринимать информацию, использовать инструменты и помогают модели якобы делать вид, что она действует самостоятельно и достигает целей.</p>
    <p class="whitespace-normal break-words"><strong>00:23:46</strong> --- Таким образом, мы переходим от обычного чата с моделью к выполнению программой каких-то определённых целей. Для конечного пользователя всё равно выглядит так, будто это просто чат с моделью, но под капотом работает много разных подпрограмм, которые отвечают за разные спектры обязанностей. Также здесь нужно поговорить про техники промптинга, потому что правильно написанный запрос, правильно написанный промпт в модель может сильно улучшить качество ответа.</p>
    <p class="whitespace-normal break-words"><strong>00:24:13</strong> --- Наверное, самая популярная на сегодняшний день техника — это Chain of Thoughts. Она может быть выполнена как в рамках написания промпта, так и через агенты, когда программы помогают разбивать на так называемые thoughts наш запрос. Суть простая. Вместо того чтобы сказать модели «сделай сразу это», например, вычисли результат вот такого-то уравнения, мы просим модель поэтапно расписать каждый шаг того, как она будет это делать, и в конце выдать результат.</p>
    <p class="whitespace-normal break-words"><strong>00:24:41</strong> --- Вот такой запрос по этапному расписыванию, то есть чтобы она выписала цепочку своих мыслей, тот самый chain of thoughts, это сильно улучшает финальный ответ от модели. Имплементации могут быть разные, но суть одна и та же: опиши мне по цепочке, как ты будешь делать эту задачу, а дальше делай. Дальше наверняка вы слышали так называемый shot-prompting: zero-shot, one-shot, multi-shot-prompting.</p>
    <p class="whitespace-normal break-words"><strong>00:25:06</strong> --- Это когда в модель отправляем примеры того, как она должна ответить. Это тоже очень сильно улучшает качество ответа модели. Помните, в самом начале я рассказывал, что надо в запросе, в промпте, прописывать актора, нужно прописывать формат ответа, нужно прописывать ограничения. Так вот, к этому ещё можно добавить техники промптинга. Zero-shot, one-shot и many, либо few-shot — это всё про shot-prompting. Zero-shot — это просто когда отправили пустой промпт, то есть никаких вариантов ответа мы не дали нашей LLM посмотреть.</p>
    <p class="whitespace-normal break-words"><strong>00:25:39</strong> --- One-Shot Prompting — это когда подали вместе с промптом ещё и пример того, как должен выглядеть ответ. Не просто описательный, а, например, подаём примеры решения формулы. Просим: «Пожалуйста, реши вот эту формулу», и в конце добавляем пример похожей формулы, как она решается. Вот вам, пожалуйста, уже One-Shot Prompting.</p>
    <p class="whitespace-normal break-words"><strong>00:26:00</strong> --- Few-Shot Prompting — это когда много примеров подаём на вход. Собственно, чем больше примеров, тем лучше модель понимает у себя под капотом, как подходить к этой задаче. У неё есть перед глазами примеры, и она по образу и подобию отвечает. Есть ещё методика под названием self-consistency, либо самосогласованность. Это когда просим модель подумать над несколькими вариантами и выбрать тот из них, который лучше всего будет подходить под критерии запроса.</p>
    <p class="whitespace-normal break-words"><strong>00:26:30</strong> --- Таким образом, опять модель просим под капотом подумать чуть лучше, немножко другим способом, нежели это работает в chain of thoughts, но, тем не менее, self-consistency также сильно улучшает ответ модели. Если вы когда-то подавали на вход модели конкретные инструкции, типа текстовой блок-схемы — сначала сделай это, потом это, потом это, — то для этого тоже есть название. Это называется instruction prompting.</p>
    <p class="whitespace-normal break-words"><strong>00:26:57</strong> --- Ну, есть техники посложнее, например, ReAct, почти как в JavaScript, но опять не про JavaScript. Переводится как Reason plus Act. Это когда просим модель и подумать, и заодно сходить куда-нибудь на внешний источник, например, с помощью агентов, и завалидировать результат, который она получила, и уже после этого выдать финальный результат. В общем, техник промптинга великое множество. Их постоянно придумывают новые, какие-то лайфхаки, новые модели выходят с рекомендациями от компании.</p>
    <p class="whitespace-normal break-words"><strong>00:27:26</strong> --- Есть, конечно, устоявшиеся техники. Вот, например, те, про которые я рассказал, которые плюс-минус на все модели LLM распространяются. Есть суперспецифичные — про все их не хватит и нескольких часов, чтобы рассказать. Поэтому советую пройти на promptguide.ai. Это замечательный сайт, на котором можно почитать про очень много промптинг-техник и прокачать свой навык написания промптов. Это, наверное, самое простое, что может сильно улучшить результат ответа вашей модели.</p>
    <p class="whitespace-normal break-words"><strong>00:27:53</strong> --- Вам не надо писать код дополнительный, вам не надо заморачиваться со сложными процессами сбора данных, обучения. Вам просто нужно понимать, каким образом можно лучше написать промпт, чтобы получить более качественный ответ. Это всё про промптинг, про промпт-инженерию в целом. Приближаемся к концу. Когда начинаете работать с LLM, то так или иначе сталкиваетесь не только с базовыми библиотеками, не только с техниками промптинга, но и в какой-то момент сталкиваетесь с вполне себе прикладными библиотеками, которые помогают решать конкретно вашу задачу.</p>
    <p class="whitespace-normal break-words"><strong>00:28:23</strong> --- Тут тоже можно часами рассказывать про эти библиотеки. Хочу упомянуть буквально два типа этих библиотек, буквально три библиотеки. Про первую я уже сегодня рассказывал.</p>
    <p class="whitespace-normal break-words"><strong>00:28:52</strong> --- Это Llama CPP, и библиотека эта является по сути инференсом для моделей, которые могут запускаться на CPU, то есть не на графических ускорителях, а на обычных центральных процессорах. Кроме того, Llama CPP даёт возможность квантовать модели, делать квантизацию, что тоже часто, очень часто пригождается.</p>
    <p class="whitespace-normal break-words"><strong>00:29:17</strong> --- Довольно широкий спектр задач получается у Llama CPP. Плюс Llama CPP настолько популярна и монопольна на рынке запуска моделей на CPU, что она используется под капотом практически у всего, что запускает модель на CPU. Это и Ollama, и LLaMA Studio. Можно тоже Llama CPP выбирать. Полезно знать, что это за библиотека. Даже, может быть, будет полезно её прям запустить и попробовать прям на ней исконно запускать модельки без каких-то прослоек.</p>
    <p class="whitespace-normal break-words"><strong>00:29:46</strong> --- Второй тип прикладных библиотек — это библиотеки, которые позволяют выстраивать пайплайны работы с LLM. Тут выделю, наверное, LangChain, а также LangGraph и LangSmith. У нас, кстати, был классный воркшоп по всем этим трём инструментам. LangChain и LangGraph — это инструменты, позволяющие на Python в очень удобном формате, в первом случае в виде цепочки, во втором случае в виде графа, выстраивать взаимоотношения данных, LLM и других источников данных в рамках одного Python-приложения.</p>
    <p class="whitespace-normal break-words"><strong>00:30:05</strong> --- То есть полноценный фреймворк для создания LLM-based-приложений. И есть ещё Llama Index — это отдельная тоже опенсорсная библиотека, которая специализируется именно на интеграции источников данных с LLM. Поэтому тоже обратите на них внимание. Скорее всего, с какой-то из этих библиотек вы будете плотно взаимодействовать.</p>
    <p class="whitespace-normal break-words"><strong>00:30:37</strong> --- Надо сказать, что у них есть аналоги менее популярные, например, там Autogen есть, который можно использовать в том числе, как и LangChain, и куча-куча всяких фреймворков. Вы можете найти, кстати, многие из них у нас на канале «Инструменты». Просто введите в поиске на канале хэштег <code class="bg-text-200/5 border border-0.5 border-border-300 text-danger-000 whitespace-pre-wrap rounded-[0.4rem] px-1 py-px text-[0.9rem]">#agent</code>, и вы найдёте много прикладных библиотек, позволяющих строить агентное приложение. Потому что когда к LLM подключаешь базу данных, когда в pipeline с LLM встраиваешь какие-нибудь техники промптинга, то это по факту очень похоже на настройку агентов. По факту под капотом запускаешь подпрограммы, которые спаривают твою LLM с базой данных, с поиском, с чем-нибудь ещё. Это суть агентного подхода.</p>
    <p class="whitespace-normal break-words"><strong>00:31:04</strong> --- Ну и в конце стоит упомянуть про API базовых закрытых самых мощных моделей. Потому что, конечно, вы можете в своих проектах использовать локальные модели, для этого использовать тот же Llama CPP либо другие фреймворки для запуска модели на GPU. Но навряд ли ваш конечный пользователь будет иметь мощное железо. Хотя, конечно, в случае с SaaS это возможно. Но в общем-то, как работать с open-source моделями, нам уже более-менее понятно. Там есть TensorFlow, PyTorch, ONNX, Llama CPP, всё что угодно. Но лучший результат показывают в приложениях закрытые модели. Недаром на них тратят миллион-миллиардов денег на обучение, недаром их веса никому не показывают, ну потому что они очень дорогие, и поэтому доступ к ним продаётся через API.</p>
    <p class="whitespace-normal break-words"><strong>00:31:29</strong> --- Я думаю, все из вас знают основные API, но просто здесь перечислю, чтобы осталось на видео, чтобы те из вас, кто не знают, узнали про них. Первым делом это OpenAI API. OpenAI API — самое популярное API, которое даёт доступ ко всем моделям компании OpenAI: это и GPT-4.0, и старые GPT, и O1. Также OpenAI API даёт доступ к Real-Time API, позволяющему устроить голосовые общения, к text-to-speech моделям, к DALL-E. Ко всем инструментам, которые OpenAI даёт, он даёт доступ через OpenAI API. Доступ там очень просто получить: денежку закинул и пользуешься.</p>
    <p class="whitespace-normal break-words"><strong>00:31:56</strong> --- Второй, а может даже для кого-то и первый по значимости API — это API Anthropic. Из него вы получаете доступ к инструментам от Anthropic, в том числе ко всем моделям семейства Claude. И к Claude 3.5 Sonnet тоже там же вы доступ получите.</p>
    <p class="whitespace-normal break-words"><strong>00:32:24</strong> --- Ну и третий по популярности и значимости — это Gemini API. Он же, наверное, Google AI API можно его назвать. Но это API, который предоставляет доступ к моделям семейства Google. Напутал. К моделям семейства Gemini Google, так будет правильнее.</p>
    <p class="whitespace-normal break-words"><strong>00:32:49</strong> --- Особнячком хочу выделить LaPlatform. LaPlatform — это API компании Mistral. Mistral, я, наверное, не ошибусь, если скажу, что делает четвёртые по мощности модели, пусть и сильно стоящие от тройки лидеров. Но, тем не менее, про LaPlatform знать полезно, плюс у них очень приятные цены и довольно часто есть классные акции, когда они выкатывают новые модели. Часто они практически за бесценок доступны.</p>
    <p class="whitespace-normal break-words"><strong>00:33:18</strong> --- Примерно на этом же уровне, на уровне Mistral, в последнее время получают популярность API от компании Cohere. И у них есть свои модели. Они отлично работают с генерацией текста и с embeddings. Так что, если нужно что-то из этого, то обратите внимание на Cohere API. Цены там тоже приятные. Ну и вообще этих API много. Я, может, сделаю отдельный пост, наверное, со сбором основных, которые я знаю. У меня там уже списочек ссылок на штук 20. Поэтому в конце скажу вам ещё про два сервиса, которые предоставляют широкий доступ к разным моделям.</p>
    <p class="whitespace-normal break-words"><strong>00:33:48</strong> --- Это Azure AI Foundry, который раньше назывался Azure AI Studio. Это единое место, где Microsoft предоставляет доступ к суперширокому спектру моделей через удобное API с интеграцией облачных сервисов от Azure. Через этот же Azure AI Foundry можно получать, естественно, доступ к новым моделям OpenAI, потому что у Microsoft тесные связи с OpenAI.</p>
    <p class="whitespace-normal break-words"><strong>00:34:18</strong> --- Ну а AWS Bedrock, либо Amazon Bedrock, он, по-моему, правильно называется. Это аналогичный сервис, но от компании Amazon, в который тесно интегрированы сервисы AWS, а также там доступны эксклюзивно модели, которые сам AWS разрабатывает — это Titan, ну и, конечно же, модели от компании Anthropic Claude. Amazon на сегодняшний день является главным партнёром Anthropic. На сегодняшний день это 7 декабря, 7 декабря 2024 года. Может что-то поменяется, когда вы это видео будете смотреть.</p>
    <p class="whitespace-normal break-words"><strong>00:34:36</strong> --- На этом мы закончили терминологию уровня Master. Я надеюсь, что было более-менее интересно и понятно. Если на слух какие-то из инструментов не поняли, не приняли, то можете быстренько чекнуть их название в описании к этому ролику, либо пойти прямиком в файлик с базовой терминологией и там найти прям всё то, что я рассказывал текстом, практически иногда слово в слово. А также там будут все ссылки на инструменты и библиотеки, про которые я вам сегодня рассказывал. На этом всё. Увидимся в следующем и последнем видео про базовую терминологию. Там уже будем говорить про философские больше термины, но которые вы тоже частенько будете слышать, сталкиваясь с миром нейронок и AI.</p>
    <p class="whitespace-normal break-words"><strong>00:35:13</strong> --- Пока-пока.</p></div></div>
</template>